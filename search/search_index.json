{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 What's 101 \u00b6 101 (pronounced ONE-oh-ONE) is a topic for beginners in any area. It has all the basic principles and concepts that are expected in a particular field. What's Kubernetes 101 \u00b6 A basic instruction for Kubernetes setup and understanding. Helping you understand core technologies. Modules \u00b6 Module ID Module - Install Kubernetes Cluster 3 Docker Core Technology 4 Kubernetes Architecture Principles and Object Design 5 Kubernetes Control Plane Component: etcd 6 Kubernetes Control Plane Component: APIServer 7 Kubernetes Control Plane Component: Scheduler and Controller 8 Kubernetes Control Plane Component: Lifecycle Management and Service Discovery 9 Managing Production-ready Kubernetes Clusters 10 DevOps with Kubernetes in Production 11 Migrating apps to Kubernetes 12 Advanced Traffic Management with Istio","title":"Overview"},{"location":"#overview","text":"","title":"Overview"},{"location":"#whats-101","text":"101 (pronounced ONE-oh-ONE) is a topic for beginners in any area. It has all the basic principles and concepts that are expected in a particular field.","title":"What's 101"},{"location":"#whats-kubernetes-101","text":"A basic instruction for Kubernetes setup and understanding. Helping you understand core technologies.","title":"What's Kubernetes 101"},{"location":"#modules","text":"Module ID Module - Install Kubernetes Cluster 3 Docker Core Technology 4 Kubernetes Architecture Principles and Object Design 5 Kubernetes Control Plane Component: etcd 6 Kubernetes Control Plane Component: APIServer 7 Kubernetes Control Plane Component: Scheduler and Controller 8 Kubernetes Control Plane Component: Lifecycle Management and Service Discovery 9 Managing Production-ready Kubernetes Clusters 10 DevOps with Kubernetes in Production 11 Migrating apps to Kubernetes 12 Advanced Traffic Management with Istio","title":"Modules"},{"location":"install-kubernetes-cluster/","text":"Install Kubernetes Cluster \u00b6 For learning Kubernetes and the Kubernetes ecosystem, installing a cluster is only a very small part of its learning process. During the learning process, a clean cluster has the usage to allow us to perform various different experiments or tests. But objectively speaking, installing a Kubernetes cluster is not an easy task for beginners. In this post, several methods of installing a Kubernetes cluster will be given. kubeadm \u00b6 \u901a\u8fc7 kubeadm \u5b89\u88c5\uff0c\u9700\u8981\u624b\u5de5\u5b89\u88c5 docker\uff0ckubelet\uff0ckubeadm \u7b49 kind \u00b6 \u901a\u8fc7 kind \u5b89\u88c5\uff0c\u5168\u81ea\u52a8\uff0c\u65e0\u624b\u5de5\u6b65\u9aa4\uff0c\u5feb\u6377\u7b80\u5355\uff0c\u4f46\u662f\u8282\u70b9\u662f\u57fa\u4e8e\u5bb9\u5668\u800c\u4e0d\u662f\u865a\u62df\u673a\u7684\u3002 minikube \u00b6 \u901a\u8fc7 minikube \u5b89\u88c5\u3002 Vagrant \u00b6 \u5982\u679c\u914d\u7f6e kubeadm \u6709\u56f0\u96be\u53ef\u53c2\u8003 Vagrantfile \u8de8\u516c\u7f51\u5b89\u88c5\u96c6\u7fa4 \u00b6 \u5229\u7528 Kilo \u8de8\u516c\u7f51\u7ec4\u5efa k3s \u96c6\u7fa4 \u5229\u7528 FabEdge \u8de8\u516c\u7f51\u7ec4\u5efa k3s \u96c6\u7fa4","title":"Overview"},{"location":"install-kubernetes-cluster/#install-kubernetes-cluster","text":"For learning Kubernetes and the Kubernetes ecosystem, installing a cluster is only a very small part of its learning process. During the learning process, a clean cluster has the usage to allow us to perform various different experiments or tests. But objectively speaking, installing a Kubernetes cluster is not an easy task for beginners. In this post, several methods of installing a Kubernetes cluster will be given.","title":"Install Kubernetes Cluster"},{"location":"install-kubernetes-cluster/#kubeadm","text":"\u901a\u8fc7 kubeadm \u5b89\u88c5\uff0c\u9700\u8981\u624b\u5de5\u5b89\u88c5 docker\uff0ckubelet\uff0ckubeadm \u7b49","title":"kubeadm"},{"location":"install-kubernetes-cluster/#kind","text":"\u901a\u8fc7 kind \u5b89\u88c5\uff0c\u5168\u81ea\u52a8\uff0c\u65e0\u624b\u5de5\u6b65\u9aa4\uff0c\u5feb\u6377\u7b80\u5355\uff0c\u4f46\u662f\u8282\u70b9\u662f\u57fa\u4e8e\u5bb9\u5668\u800c\u4e0d\u662f\u865a\u62df\u673a\u7684\u3002","title":"kind"},{"location":"install-kubernetes-cluster/#minikube","text":"\u901a\u8fc7 minikube \u5b89\u88c5\u3002","title":"minikube"},{"location":"install-kubernetes-cluster/#vagrant","text":"\u5982\u679c\u914d\u7f6e kubeadm \u6709\u56f0\u96be\u53ef\u53c2\u8003 Vagrantfile","title":"Vagrant"},{"location":"install-kubernetes-cluster/#_1","text":"\u5229\u7528 Kilo \u8de8\u516c\u7f51\u7ec4\u5efa k3s \u96c6\u7fa4 \u5229\u7528 FabEdge \u8de8\u516c\u7f51\u7ec4\u5efa k3s \u96c6\u7fa4","title":"\u8de8\u516c\u7f51\u5b89\u88c5\u96c6\u7fa4"},{"location":"install-kubernetes-cluster/kind/","text":"Kind \u00b6 What's kind \u00b6 kind is a tool for running local Kubernetes clusters using Docker container \u201cnodes\u201d. kind was primarily designed for testing Kubernetes itself, but may be used for local development or CI. Create kind cluster on mac \u00b6 brew install kind kind create cluster Reference: https://kind.sigs.k8s.io/docs/user/quick-start/#installation Install Kind \u00b6 Tip Reference: Kind Installation macOS Linux Windows brew install kind curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.12.0/kind-linux-amd64 chmod +x ./kind mv ./kind /some-dir-in-your-PATH/kind curl . exe -Lo kind-windows-amd64 . exe https :// kind . sigs . k8s . io / dl / v0 . 12 . 0 / kind-windows-amd64 Move-Item .\\ kind-windows-amd64 . exe c :\\ some-dir-in-your-PATH \\ kind . exe Creating a Cluster \u00b6 Tip If network hard to access the dockerhub, you can use mirror image. Default Image Mirror Image kind create cluster kind create cluster --image docker.m.daocloud.io/kindest/node:v1.17.0 Check your Cluster \u00b6 kubectl cluster-info --context kind-kind","title":"Kind"},{"location":"install-kubernetes-cluster/kind/#kind","text":"","title":"Kind"},{"location":"install-kubernetes-cluster/kind/#whats-kind","text":"kind is a tool for running local Kubernetes clusters using Docker container \u201cnodes\u201d. kind was primarily designed for testing Kubernetes itself, but may be used for local development or CI.","title":"What's kind"},{"location":"install-kubernetes-cluster/kind/#create-kind-cluster-on-mac","text":"brew install kind kind create cluster Reference: https://kind.sigs.k8s.io/docs/user/quick-start/#installation","title":"Create kind cluster on mac"},{"location":"install-kubernetes-cluster/kind/#install-kind","text":"Tip Reference: Kind Installation macOS Linux Windows brew install kind curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.12.0/kind-linux-amd64 chmod +x ./kind mv ./kind /some-dir-in-your-PATH/kind curl . exe -Lo kind-windows-amd64 . exe https :// kind . sigs . k8s . io / dl / v0 . 12 . 0 / kind-windows-amd64 Move-Item .\\ kind-windows-amd64 . exe c :\\ some-dir-in-your-PATH \\ kind . exe","title":"Install Kind"},{"location":"install-kubernetes-cluster/kind/#creating-a-cluster","text":"Tip If network hard to access the dockerhub, you can use mirror image. Default Image Mirror Image kind create cluster kind create cluster --image docker.m.daocloud.io/kindest/node:v1.17.0","title":"Creating a Cluster"},{"location":"install-kubernetes-cluster/kind/#check-your-cluster","text":"kubectl cluster-info --context kind-kind","title":"Check your Cluster"},{"location":"install-kubernetes-cluster/kubeadm/","text":"Kubeadm \u00b6 What's Kubeadm \u00b6 Kubeadm is ...","title":"Kubeadm"},{"location":"install-kubernetes-cluster/kubeadm/#kubeadm","text":"","title":"Kubeadm"},{"location":"install-kubernetes-cluster/kubeadm/#whats-kubeadm","text":"Kubeadm is ...","title":"What's Kubeadm"},{"location":"install-kubernetes-cluster/minikube/","text":"Minikube \u00b6 Setup local env for Mac \u00b6 https://minikube.sigs.k8s.io/docs/ Mac \u00b6 Install docker \u00b6 $ brew install docker Install Hypervisor(amd) \u00b6 Install hyperkit https://minikube.sigs.k8s.io/docs/drivers/hyperkit/ $ git clone https://github.com/moby/hyperkit.git $ cd hyperkit $ make $ cp ./build/hyperkit /usr/local/bin/hyperkit Download minikube https://github.com/kubernetes/minikube/releases \u00b6 minikube url list https://github.com/kubernetes/minikube/releases/ (arm | amd) \u00b6 For MacOS amd $ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 \\ && chmod +x minikube $ sudo mv minikube /usr/local/bin Config minikube \u00b6 hyperkit doesn't support mac(arm64) \u00b6 ## $ minikube config set driver docker $ minikube config set driver hyperkit Start minikube \u00b6 $ minikube start \\ --cpus = 8 \\ --v = 4 \\ --memory = 8192 \\ --network-plugin = cni \\ --enable-default-cni \\ --bootstrapper = kubeadm \\ --kubernetes-version v1.18.3 \\ --image-mirror-country = cn \\ --image-repository = registry.cn-hangzhou.aliyuncs.com/google_containers Install kubectl \u00b6 https://kubernetes.io/releases/ \u00b6 Download kubectl for Mac, unzip and put into your OS path $ curl -LO https://dl.k8s.io/v1.18.6/kubernetes-client-darwin-amd64.tar.gz Setup local env for Linux \u00b6 https://minikube.sigs.k8s.io/docs/ Install docker \u00b6 Ubuntu: $ sudo apt-get install docker.io CentOS: $ sudo yum install docker-ce Install VMtool \u00b6 For Linux Install VirtualBox, access and find right version for your OS https://www.virtualbox.org/wiki/Linux_Downloads Download minikube https://github.com/kubernetes/minikube/releases \u00b6 For Linux $ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube sudo install minikube /usr/local/bin/ Config minikube \u00b6 $ minikube config set driver virtualbox Start minikube \u00b6 $ minikube start \\ --cpus = 8 \\ --v = 4 \\ --memory = 8192 \\ --network-plugin = cni \\ --enable-default-cni \\ --bootstrapper = kubeadm \\ --kubernetes-version v1.18.3 \\ --image-mirror-country = cn \\ --image-repository = registry.cn-hangzhou.aliyuncs.com/google_containers Install kubectl \u00b6 Download kubectl for Linux $ curl -LO https://dl.k8s.io/v1.18.6/kubernetes-client-linux-amd64.tar.gz","title":"Minikube"},{"location":"install-kubernetes-cluster/minikube/#minikube","text":"","title":"Minikube"},{"location":"install-kubernetes-cluster/minikube/#setup-local-env-for-mac","text":"https://minikube.sigs.k8s.io/docs/","title":"Setup local env for Mac"},{"location":"install-kubernetes-cluster/minikube/#mac","text":"","title":"Mac"},{"location":"install-kubernetes-cluster/minikube/#install-docker","text":"$ brew install docker","title":"Install docker"},{"location":"install-kubernetes-cluster/minikube/#install-hypervisoramd","text":"Install hyperkit https://minikube.sigs.k8s.io/docs/drivers/hyperkit/ $ git clone https://github.com/moby/hyperkit.git $ cd hyperkit $ make $ cp ./build/hyperkit /usr/local/bin/hyperkit","title":"Install Hypervisor(amd)"},{"location":"install-kubernetes-cluster/minikube/#download-minikube-httpsgithubcomkubernetesminikubereleases","text":"","title":"Download minikube https://github.com/kubernetes/minikube/releases"},{"location":"install-kubernetes-cluster/minikube/#minikube-url-list-httpsgithubcomkubernetesminikubereleases-arm-amd","text":"For MacOS amd $ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 \\ && chmod +x minikube $ sudo mv minikube /usr/local/bin","title":"minikube url list https://github.com/kubernetes/minikube/releases/ (arm | amd)"},{"location":"install-kubernetes-cluster/minikube/#config-minikube","text":"","title":"Config minikube"},{"location":"install-kubernetes-cluster/minikube/#hyperkit-doesnt-support-macarm64","text":"## $ minikube config set driver docker $ minikube config set driver hyperkit","title":"hyperkit doesn't support mac(arm64)"},{"location":"install-kubernetes-cluster/minikube/#start-minikube","text":"$ minikube start \\ --cpus = 8 \\ --v = 4 \\ --memory = 8192 \\ --network-plugin = cni \\ --enable-default-cni \\ --bootstrapper = kubeadm \\ --kubernetes-version v1.18.3 \\ --image-mirror-country = cn \\ --image-repository = registry.cn-hangzhou.aliyuncs.com/google_containers","title":"Start minikube"},{"location":"install-kubernetes-cluster/minikube/#install-kubectl","text":"","title":"Install kubectl"},{"location":"install-kubernetes-cluster/minikube/#httpskubernetesioreleases","text":"Download kubectl for Mac, unzip and put into your OS path $ curl -LO https://dl.k8s.io/v1.18.6/kubernetes-client-darwin-amd64.tar.gz","title":"https://kubernetes.io/releases/"},{"location":"install-kubernetes-cluster/minikube/#setup-local-env-for-linux","text":"https://minikube.sigs.k8s.io/docs/","title":"Setup local env for Linux"},{"location":"install-kubernetes-cluster/minikube/#install-docker_1","text":"Ubuntu: $ sudo apt-get install docker.io CentOS: $ sudo yum install docker-ce","title":"Install docker"},{"location":"install-kubernetes-cluster/minikube/#install-vmtool","text":"For Linux Install VirtualBox, access and find right version for your OS https://www.virtualbox.org/wiki/Linux_Downloads","title":"Install VMtool"},{"location":"install-kubernetes-cluster/minikube/#download-minikube-httpsgithubcomkubernetesminikubereleases_1","text":"For Linux $ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube sudo install minikube /usr/local/bin/","title":"Download minikube https://github.com/kubernetes/minikube/releases"},{"location":"install-kubernetes-cluster/minikube/#config-minikube_1","text":"$ minikube config set driver virtualbox","title":"Config minikube"},{"location":"install-kubernetes-cluster/minikube/#start-minikube_1","text":"$ minikube start \\ --cpus = 8 \\ --v = 4 \\ --memory = 8192 \\ --network-plugin = cni \\ --enable-default-cni \\ --bootstrapper = kubeadm \\ --kubernetes-version v1.18.3 \\ --image-mirror-country = cn \\ --image-repository = registry.cn-hangzhou.aliyuncs.com/google_containers","title":"Start minikube"},{"location":"install-kubernetes-cluster/minikube/#install-kubectl_1","text":"Download kubectl for Linux $ curl -LO https://dl.k8s.io/v1.18.6/kubernetes-client-linux-amd64.tar.gz","title":"Install kubectl"},{"location":"install-kubernetes-cluster/vagrant/","text":"Vagrant \u00b6 Warning Because of Apple's restrictions, higher versions of macOS will have greater limitations on Virtualbox. If you use Virtualbox for Vagrant provider, that will be full of strange questions. Prerequisites \u00b6 Vagrant Virtualbox What's Vagrant \u00b6 Vagrant - the command line utility for managing the lifecycle of virtual machines. What's Virtualbox \u00b6 VirtualBox is a general-purpose full virtualizer for x86 hardware, targeted at server, desktop and embedded use. Vagrant Config \u00b6 echo \"Create dir to store vagrant configuration\" mkdir -p ~/k8s-vagrant/ echo \"Generate vagrant configuration\" cat <<EOF | tee ~/k8s-vagrant/Vagrantfile # -*- mode: ruby -*- # vi: set ft=ruby : # \u4f7f\u7528\u65b9\u6cd5 # 1. \u5b89\u88c5 virtualbox # 2. \u5b89\u88c5 vagrant # 3. \u6dfb\u52a0\u955c\u50cf\uff08\u53ef\u9009\uff0c\u9002\u7528\u4e8e\u7f51\u7edc\u4e0d\u597d\u7684\u72b6\u51b5\uff09 # 4. vagrant up # 5. vagrant ssh \u5373\u53ef\uff08\u9ed8\u8ba4\u7528\u6237\u540d vagrant\uff0c\u6709 sudo \u6267\u884c\u6743\u9650\uff09 Vagrant.configure(\"2\") do |config| config.vm.box = \"ubuntu/focal64\" config.vm.box_check_update = false config.vm.network \"private_network\", ip: \"192.168.34.2\", name: \"vboxnet0\" config.vm.provider \"virtualbox\" do |vb| # \u914d\u7f6e\u865a\u62df\u673a\u4e3a 4 \u4e2a\u6838\u5fc3\uff0c6GB \u5185\u5b58 vb.cpus = 4 vb.memory = \"6144\" end config.vm.provision \"shell\", inline: <<-SHELL sed -i 's/archive.ubuntu.com/mirrors.ustc.edu.cn/g' /etc/apt/sources.list apt-get update apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | apt-key add - add-apt-repository \\ \"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" echo \"deb https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main\" > /etc/apt/sources.list.d/kubernetes.list curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add apt-get update apt-get install -y docker-ce docker-ce-cli containerd.io apt-get install -y kubelet=1.19.15-00 kubeadm=1.19.15-00 kubectl=1.19.15-00 apt-mark hold kubelet kubeadm kubectl adduser vagrant docker SHELL end EOF Initial VM \u00b6 vagrant up Connect to the VM \u00b6 vagrant ssh","title":"Vagrant"},{"location":"install-kubernetes-cluster/vagrant/#vagrant","text":"Warning Because of Apple's restrictions, higher versions of macOS will have greater limitations on Virtualbox. If you use Virtualbox for Vagrant provider, that will be full of strange questions.","title":"Vagrant"},{"location":"install-kubernetes-cluster/vagrant/#prerequisites","text":"Vagrant Virtualbox","title":"Prerequisites"},{"location":"install-kubernetes-cluster/vagrant/#whats-vagrant","text":"Vagrant - the command line utility for managing the lifecycle of virtual machines.","title":"What's Vagrant"},{"location":"install-kubernetes-cluster/vagrant/#whats-virtualbox","text":"VirtualBox is a general-purpose full virtualizer for x86 hardware, targeted at server, desktop and embedded use.","title":"What's Virtualbox"},{"location":"install-kubernetes-cluster/vagrant/#vagrant-config","text":"echo \"Create dir to store vagrant configuration\" mkdir -p ~/k8s-vagrant/ echo \"Generate vagrant configuration\" cat <<EOF | tee ~/k8s-vagrant/Vagrantfile # -*- mode: ruby -*- # vi: set ft=ruby : # \u4f7f\u7528\u65b9\u6cd5 # 1. \u5b89\u88c5 virtualbox # 2. \u5b89\u88c5 vagrant # 3. \u6dfb\u52a0\u955c\u50cf\uff08\u53ef\u9009\uff0c\u9002\u7528\u4e8e\u7f51\u7edc\u4e0d\u597d\u7684\u72b6\u51b5\uff09 # 4. vagrant up # 5. vagrant ssh \u5373\u53ef\uff08\u9ed8\u8ba4\u7528\u6237\u540d vagrant\uff0c\u6709 sudo \u6267\u884c\u6743\u9650\uff09 Vagrant.configure(\"2\") do |config| config.vm.box = \"ubuntu/focal64\" config.vm.box_check_update = false config.vm.network \"private_network\", ip: \"192.168.34.2\", name: \"vboxnet0\" config.vm.provider \"virtualbox\" do |vb| # \u914d\u7f6e\u865a\u62df\u673a\u4e3a 4 \u4e2a\u6838\u5fc3\uff0c6GB \u5185\u5b58 vb.cpus = 4 vb.memory = \"6144\" end config.vm.provision \"shell\", inline: <<-SHELL sed -i 's/archive.ubuntu.com/mirrors.ustc.edu.cn/g' /etc/apt/sources.list apt-get update apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | apt-key add - add-apt-repository \\ \"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" echo \"deb https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main\" > /etc/apt/sources.list.d/kubernetes.list curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add apt-get update apt-get install -y docker-ce docker-ce-cli containerd.io apt-get install -y kubelet=1.19.15-00 kubeadm=1.19.15-00 kubectl=1.19.15-00 apt-mark hold kubelet kubeadm kubectl adduser vagrant docker SHELL end EOF","title":"Vagrant Config"},{"location":"install-kubernetes-cluster/vagrant/#initial-vm","text":"vagrant up","title":"Initial VM"},{"location":"install-kubernetes-cluster/vagrant/#connect-to-the-vm","text":"vagrant ssh","title":"Connect to the VM"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/","text":"Preparation \u00b6 virtualbox6.1 centos iso Install \u00b6 virtualbox \u00b6 create a new box name folder path type: Linux version: Other Linux (64-bit) memory 4096M cpu number:2 peak load: 100% hard disk create a virtual hard disk now choose VDI Fixed size 100GB network adapter1 Attached to: NAT Advanced: default notice: remember MAC Address (080027A71D80), we could use it later for linux setting adapter2 Attached to: Host-only Adapter Name: vboxnet0 advanced:default notice: remember MAC Address(0800271EED5C) , we could use it later for linux setting set iso file choose your box, right click it, then choose setting storage choose the logo which is like a CD Attributes => Optical Drive: (click the CD logo and choose your centos iso file) centos7 \u00b6 double click your box start (you could make sure the ios again) install centos7 language:English Date&Time: Asia/Shanghai System Installation destination: choose your vdi Begin installation Root password reboot login set network adapter vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 HWADDR=08:00:27:0A:E8:8F TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=dhcp DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s3 UUID=a88c90f7-f616-48ab-ba82-335c2d5c652d DEVICE=enp0s3 ONBOOT=yes vi /etc/sysconfig/network-scripts/ifcfg-enp0s8 HWADDR=08:00:27:DC:76:AA TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s8 // Note that it is consistent with the file name suffix UUID=a88c90f7-f616-48ab-ba82-335c2d5c652d DEVICE=enp0s8 // Note that it is consistent with the file name suffix ONBOOT=yes NM_CONTROLLED=yes IPADDR=192.168.56.200 NETMASK=255.255.255.0 GATEWAY=192.168.56.1 DNS1=8.8.8.8 vi /etc/hostname vm210 notice: don't use underline and special characters vi /etc/hosts 192.168.56.210 vm210 192.168.56.211 vm211 192.168.56.212 vm212 shutdown -r login again ping a website you know. if you could visit it which we could make sure the network is ok now. next, you could use item2 to make the next setps, because it's quite easy to edit your content. iptables cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system firewall systemctl stop firewalld systemctl disable firewalld systemctl status firewalld SELinux vi /etc/selinux/config # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. #SELINUX=enforcing # SELINUXTYPE= can take one of three values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. #SELINUXTYPE=targeted SELINUX=disabled swap // temp turn off [root@vm210 ~]# swapoff -a // Permanently turn off [root@vm210 ~]# vi /etc/fstab # # /etc/fstab # Created by anaconda on Sun Aug 22 00:58:48 2021 # # Accessible filesystems, by reference, are maintained under '/dev/disk' # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=be6fcb6b-d425-4cc6-9e97-0bba2b1c7236 /boot xfs defaults 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 #/dev/mapper/centos-swap swap swap defaults 0 0 // Comment out the current line [root@vm210 ~]# shutdown -r timezone sync yum install ntp systemctl enable ntpd systemctl start ntpd timedatectl set-timezone Asia/Shanghai timedatectl set-ntp yes ntpq -p kubedam \u00b6 install docker note\uff1adon't install docker with centos, you should choose docker-ce yum source vi /etc/yum.repos.d/kubernetes.repo # choose the right baseurl which you feel better in your country. [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=0 kubelet kubeadm install yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet system starts docker systemctl enable docker && systemctl start docker kubeadm [root@vm210 ~]# kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.22.0 --apiserver-advertise-address=192.168.56.130 [init] Using Kubernetes version: v1.22.0 [preflight] Running pre-flight checks error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2 [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher [root@vm210 ~]# kubelet --cgroupDriver E0821 18:06:43.647211 8799 server.go:158] \"Failed to parse kubelet flag\" err=\"unknown flag: --cgroupDriver\" [root@vm210 ~]# systemctl status kubelet \u25cf kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /usr/lib/systemd/system/kubelet.service.d \u2514\u250010-kubeadm.conf Active: activating (auto-restart) (Result: exit-code) since \u516d 2021-08-21 18:19:45 CST; 5s ago Docs: https://kubernetes.io/docs/ Process: 8186 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE) Main PID: 8186 (code=exited, status=1/FAILURE) 8\u6708 21 18:19:45 vm210 systemd[1]: kubelet.service: main process exited, code=exited, status=1/FAILURE 8\u6708 21 18:19:45 vm210 systemd[1]: Unit kubelet.service entered failed state. 8\u6708 21 18:19:45 vm210 systemd[1]: kubelet.service failed. [root@vm210 ~]#vim /etc/docker/daemon.json { \"exec-opts\": [\"native.cgroupdriver=systemd\"] } [root@vm210 ~]#systemctl daemon-reload [root@vm210 ~]#systemctl restart docker // unable to configure the Docker daemon with file /etc/docker/daemon.json // choose to install docker-ce will solve this problem. [root@vm210 ~]#systemctl restart kubelet // run kuebeadm again ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? errors pretty printing info , error: exit status 1 [ERROR Service-Docker]: docker service is not active, please run 'systemctl start docker.service' [root@vm210 ~]#systemctl start docker.service error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR ImagePull]: failed to pull image registry.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown [root@vm210 ~]# docker pull coredns/coredns Using default tag: latest latest: Pulling from coredns/coredns c6568d217a00: Pull complete bc38a22c706b: Pull complete Digest: sha256:6e5a02c21641597998b4be7cb5eb1e7b02c0d8d23cce4dd09f4682d463798890 Status: Downloaded newer image for coredns/coredns:latest docker.io/coredns/coredns:latest [root@vm210 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.aliyuncs.com/google_containers/kube-apiserver v1.22.0 838d692cbe28 2 weeks ago 128MB registry.aliyuncs.com/google_containers/kube-controller-manager v1.22.0 5344f96781f4 2 weeks ago 122MB registry.aliyuncs.com/google_containers/kube-proxy v1.22.0 bbad1636b30d 2 weeks ago 104MB registry.aliyuncs.com/google_containers/kube-scheduler v1.22.0 3db3d153007f 2 weeks ago 52.7MB registry.aliyuncs.com/google_containers/etcd 3.5.0-0 004811815584 2 months ago 295MB coredns/coredns latest 8d147537fb7d 2 months ago 47.6MB registry.aliyuncs.com/google_containers/pause 3.5 ed210e3e4a5b 5 months ago 683kB [root@vm210 ~]# docker tag coredns/coredns:latest registry.aliyuncs.com/google_containers/coredns:v1.8.4 [root@vm210 ~]# docker rmi coredns/coredns:latest // success infomation Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.56.130:6443 --token i36hnn.8trjybo0msel27y6 \\ --discovery-token-ca-cert-hash sha256:4667ecb1cbe7692b8bef1d3fac79be22a8cf3d2086f8fd5538e00fb2b08b9ee3 clusters // master kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-7f6cbbb7b8-9mg2x 0/1 Pending 0 8h kube-system coredns-7f6cbbb7b8-fldxl 0/1 Pending 0 8h kube-system etcd-vm210 1/1 Running 4 (25m ago) 8h kube-system kube-apiserver-vm210 1/1 Running 3 (25m ago) 8h kube-system kube-controller-manager-vm210 1/1 Running 2 (25m ago) 8h kube-system kube-proxy-562x7 1/1 Running 1 (25m ago) 8h kube-system kube-proxy-dnwth 1/1 Running 1 95m kube-system kube-proxy-w2vth 1/1 Running 0 54m kube-system kube-scheduler-vm210 1/1 Running 5 (25m ago) 8h You must deploy a Container Network Interface (CNI) based Pod network add-on so that your Pods can communicate with each other. Cluster DNS (CoreDNS) will not start up before a network is installed. [root@vm210 ~]# kuletadm reset [root@vm210 ~]# kubeadm init --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.22.0 \\ --apiserver-advertise-address=192.168.56.210 \\ --pod-network-cidr=192.168.1.0/16 [root@vm210 ~]# wget https://docs.projectcalico.org/manifests/tigera-operator.yaml [root@vm210 ~]# wget https://docs.projectcalico.org/manifests/custom-resources.yaml // you should let the cidr match your network range, don not use the url to install directly. [root@vm210 ~]# vim custom-resources.yaml cidr: 192.168.0.0/16 => cidr: 192.168.1.0/16 [root@vm210 ~]# kubectl create -f tigera-operator.yaml [root@vm210 ~]# kubectl create -f custom-resources.yaml [root@vm210 ~]# watch kubectl get pods -n calico-system Every 2.0s: kubectl get pods -n calico-system Sat Aug 21 02:22:02 2021 NAME READY STATUS RESTARTS AGE calico-kube-controllers-868b656ff4-5fh56 1/1 Running 0 56m calico-node-4729c 1/1 Running 0 56m calico-node-74xwl 1/1 Running 0 51m calico-node-fgs7j 1/1 Running 1 51m calico-typha-884bbd9c6-dd7lm 1/1 Running 1 51m calico-typha-884bbd9c6-kktwc 1/1 Running 4 51m calico-typha-884bbd9c6-xj9rc 1/1 Running 0 56m [root@vm210 ~]# watch kubectl get nodes NAME STATUS ROLES AGE VERSION vm210 Ready control-plane,master 59m v1.22.0 vm211 Ready <none> 52m v1.22.0 vm212 Ready <none> 51m v1.22.1 ------------------------------------------------------ // node1 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine yum install -y yum-utils yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io systemctl start docker yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet kubeadm join 192.168.56.210:6443 --token s2n0yr.0g5ujjrfthvjvr07 \\ --discovery-token-ca-cert-hash sha256:81974851f2e10bdb8bc401ebe2e0b16dc500bd13261342d80d9643ef4dc94a05 [root@vm210 ~]# kubectl get nodes [kubelet-check] It seems like the kubelet isn't running or healthy. [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp [::1]:10248: connect: connection refused. // solve the problem above [root@vm210 ~]#vim /etc/docker/daemon.json { \"exec-opts\": [\"native.cgroupdriver=systemd\"] } [root@vm210 ~]#systemctl daemon-reload [root@vm210 ~]#systemctl restart docker [root@vm210 ~]#systemctl restart kubelet [root@vm211 ~]# kubectl get nodes The connection to the server localhost:8080 was refused - did you specify the right host or port? kubectl version -o json kubectl cluster-info [root@vm211 ~]# kubectl cluster-info To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. The connection to the server localhost:8080 was refused - did you specify the right host or port? [root@vm210 ~] systemctl status kubelet [root@vm210 ~] journalctl -xeu kubelet // Unable to update cni config\" err=\"no networks found in /etc/cni/net.d // if you encounter this problem, just to redo all the activity above on the node. summary \u00b6 What we need to note during the entire installation process is that don't just to search the key you see with command 'systemctl status kubelet' or 'journalctl -u kubelet' we must pay more attention to the args like $KUBELET_EXTRA_ARGS when we encounter some errors. 'Process: 8998 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)' Errors \u00b6 The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp [::1]:10248: connect: connection refused. systemctl restart kubelet [root@vm210 ~]# kubelet --cgroupDriver E0820 13:16:23.223925 31791 server.go:158] \"Failed to parse kubelet flag\" err=\"unknown flag: --cgroupDriver\" EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env remove the arg cgroupDriver systemctl restart kubelet check network ip a cat /etc/resolv.conf References \u00b6 The kubelet drop-in file for systemd kubelet failed with kubelet cgroup driver: \u201ccgroupfs\u201d is different from docker cgroup driver: \u201csystemd\u201d Configuring each kubelet in your cluster using kubeadm Installing kubeadm Quickstart for Calico on Kubernetes kubeadm\u5b89\u88c5k8s\u5b8c\u6574\u6559\u7a0b","title":"Centos"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#preparation","text":"virtualbox6.1 centos iso","title":"Preparation"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#install","text":"","title":"Install"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#virtualbox","text":"create a new box name folder path type: Linux version: Other Linux (64-bit) memory 4096M cpu number:2 peak load: 100% hard disk create a virtual hard disk now choose VDI Fixed size 100GB network adapter1 Attached to: NAT Advanced: default notice: remember MAC Address (080027A71D80), we could use it later for linux setting adapter2 Attached to: Host-only Adapter Name: vboxnet0 advanced:default notice: remember MAC Address(0800271EED5C) , we could use it later for linux setting set iso file choose your box, right click it, then choose setting storage choose the logo which is like a CD Attributes => Optical Drive: (click the CD logo and choose your centos iso file)","title":"virtualbox"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#centos7","text":"double click your box start (you could make sure the ios again) install centos7 language:English Date&Time: Asia/Shanghai System Installation destination: choose your vdi Begin installation Root password reboot login set network adapter vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 HWADDR=08:00:27:0A:E8:8F TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=dhcp DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s3 UUID=a88c90f7-f616-48ab-ba82-335c2d5c652d DEVICE=enp0s3 ONBOOT=yes vi /etc/sysconfig/network-scripts/ifcfg-enp0s8 HWADDR=08:00:27:DC:76:AA TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s8 // Note that it is consistent with the file name suffix UUID=a88c90f7-f616-48ab-ba82-335c2d5c652d DEVICE=enp0s8 // Note that it is consistent with the file name suffix ONBOOT=yes NM_CONTROLLED=yes IPADDR=192.168.56.200 NETMASK=255.255.255.0 GATEWAY=192.168.56.1 DNS1=8.8.8.8 vi /etc/hostname vm210 notice: don't use underline and special characters vi /etc/hosts 192.168.56.210 vm210 192.168.56.211 vm211 192.168.56.212 vm212 shutdown -r login again ping a website you know. if you could visit it which we could make sure the network is ok now. next, you could use item2 to make the next setps, because it's quite easy to edit your content. iptables cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system firewall systemctl stop firewalld systemctl disable firewalld systemctl status firewalld SELinux vi /etc/selinux/config # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. #SELINUX=enforcing # SELINUXTYPE= can take one of three values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. #SELINUXTYPE=targeted SELINUX=disabled swap // temp turn off [root@vm210 ~]# swapoff -a // Permanently turn off [root@vm210 ~]# vi /etc/fstab # # /etc/fstab # Created by anaconda on Sun Aug 22 00:58:48 2021 # # Accessible filesystems, by reference, are maintained under '/dev/disk' # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=be6fcb6b-d425-4cc6-9e97-0bba2b1c7236 /boot xfs defaults 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 #/dev/mapper/centos-swap swap swap defaults 0 0 // Comment out the current line [root@vm210 ~]# shutdown -r timezone sync yum install ntp systemctl enable ntpd systemctl start ntpd timedatectl set-timezone Asia/Shanghai timedatectl set-ntp yes ntpq -p","title":"centos7"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#kubedam","text":"install docker note\uff1adon't install docker with centos, you should choose docker-ce yum source vi /etc/yum.repos.d/kubernetes.repo # choose the right baseurl which you feel better in your country. [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=0 kubelet kubeadm install yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet system starts docker systemctl enable docker && systemctl start docker kubeadm [root@vm210 ~]# kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.22.0 --apiserver-advertise-address=192.168.56.130 [init] Using Kubernetes version: v1.22.0 [preflight] Running pre-flight checks error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2 [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher [root@vm210 ~]# kubelet --cgroupDriver E0821 18:06:43.647211 8799 server.go:158] \"Failed to parse kubelet flag\" err=\"unknown flag: --cgroupDriver\" [root@vm210 ~]# systemctl status kubelet \u25cf kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /usr/lib/systemd/system/kubelet.service.d \u2514\u250010-kubeadm.conf Active: activating (auto-restart) (Result: exit-code) since \u516d 2021-08-21 18:19:45 CST; 5s ago Docs: https://kubernetes.io/docs/ Process: 8186 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE) Main PID: 8186 (code=exited, status=1/FAILURE) 8\u6708 21 18:19:45 vm210 systemd[1]: kubelet.service: main process exited, code=exited, status=1/FAILURE 8\u6708 21 18:19:45 vm210 systemd[1]: Unit kubelet.service entered failed state. 8\u6708 21 18:19:45 vm210 systemd[1]: kubelet.service failed. [root@vm210 ~]#vim /etc/docker/daemon.json { \"exec-opts\": [\"native.cgroupdriver=systemd\"] } [root@vm210 ~]#systemctl daemon-reload [root@vm210 ~]#systemctl restart docker // unable to configure the Docker daemon with file /etc/docker/daemon.json // choose to install docker-ce will solve this problem. [root@vm210 ~]#systemctl restart kubelet // run kuebeadm again ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? errors pretty printing info , error: exit status 1 [ERROR Service-Docker]: docker service is not active, please run 'systemctl start docker.service' [root@vm210 ~]#systemctl start docker.service error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR ImagePull]: failed to pull image registry.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown [root@vm210 ~]# docker pull coredns/coredns Using default tag: latest latest: Pulling from coredns/coredns c6568d217a00: Pull complete bc38a22c706b: Pull complete Digest: sha256:6e5a02c21641597998b4be7cb5eb1e7b02c0d8d23cce4dd09f4682d463798890 Status: Downloaded newer image for coredns/coredns:latest docker.io/coredns/coredns:latest [root@vm210 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.aliyuncs.com/google_containers/kube-apiserver v1.22.0 838d692cbe28 2 weeks ago 128MB registry.aliyuncs.com/google_containers/kube-controller-manager v1.22.0 5344f96781f4 2 weeks ago 122MB registry.aliyuncs.com/google_containers/kube-proxy v1.22.0 bbad1636b30d 2 weeks ago 104MB registry.aliyuncs.com/google_containers/kube-scheduler v1.22.0 3db3d153007f 2 weeks ago 52.7MB registry.aliyuncs.com/google_containers/etcd 3.5.0-0 004811815584 2 months ago 295MB coredns/coredns latest 8d147537fb7d 2 months ago 47.6MB registry.aliyuncs.com/google_containers/pause 3.5 ed210e3e4a5b 5 months ago 683kB [root@vm210 ~]# docker tag coredns/coredns:latest registry.aliyuncs.com/google_containers/coredns:v1.8.4 [root@vm210 ~]# docker rmi coredns/coredns:latest // success infomation Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.56.130:6443 --token i36hnn.8trjybo0msel27y6 \\ --discovery-token-ca-cert-hash sha256:4667ecb1cbe7692b8bef1d3fac79be22a8cf3d2086f8fd5538e00fb2b08b9ee3 clusters // master kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-7f6cbbb7b8-9mg2x 0/1 Pending 0 8h kube-system coredns-7f6cbbb7b8-fldxl 0/1 Pending 0 8h kube-system etcd-vm210 1/1 Running 4 (25m ago) 8h kube-system kube-apiserver-vm210 1/1 Running 3 (25m ago) 8h kube-system kube-controller-manager-vm210 1/1 Running 2 (25m ago) 8h kube-system kube-proxy-562x7 1/1 Running 1 (25m ago) 8h kube-system kube-proxy-dnwth 1/1 Running 1 95m kube-system kube-proxy-w2vth 1/1 Running 0 54m kube-system kube-scheduler-vm210 1/1 Running 5 (25m ago) 8h You must deploy a Container Network Interface (CNI) based Pod network add-on so that your Pods can communicate with each other. Cluster DNS (CoreDNS) will not start up before a network is installed. [root@vm210 ~]# kuletadm reset [root@vm210 ~]# kubeadm init --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.22.0 \\ --apiserver-advertise-address=192.168.56.210 \\ --pod-network-cidr=192.168.1.0/16 [root@vm210 ~]# wget https://docs.projectcalico.org/manifests/tigera-operator.yaml [root@vm210 ~]# wget https://docs.projectcalico.org/manifests/custom-resources.yaml // you should let the cidr match your network range, don not use the url to install directly. [root@vm210 ~]# vim custom-resources.yaml cidr: 192.168.0.0/16 => cidr: 192.168.1.0/16 [root@vm210 ~]# kubectl create -f tigera-operator.yaml [root@vm210 ~]# kubectl create -f custom-resources.yaml [root@vm210 ~]# watch kubectl get pods -n calico-system Every 2.0s: kubectl get pods -n calico-system Sat Aug 21 02:22:02 2021 NAME READY STATUS RESTARTS AGE calico-kube-controllers-868b656ff4-5fh56 1/1 Running 0 56m calico-node-4729c 1/1 Running 0 56m calico-node-74xwl 1/1 Running 0 51m calico-node-fgs7j 1/1 Running 1 51m calico-typha-884bbd9c6-dd7lm 1/1 Running 1 51m calico-typha-884bbd9c6-kktwc 1/1 Running 4 51m calico-typha-884bbd9c6-xj9rc 1/1 Running 0 56m [root@vm210 ~]# watch kubectl get nodes NAME STATUS ROLES AGE VERSION vm210 Ready control-plane,master 59m v1.22.0 vm211 Ready <none> 52m v1.22.0 vm212 Ready <none> 51m v1.22.1 ------------------------------------------------------ // node1 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine yum install -y yum-utils yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io systemctl start docker yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet kubeadm join 192.168.56.210:6443 --token s2n0yr.0g5ujjrfthvjvr07 \\ --discovery-token-ca-cert-hash sha256:81974851f2e10bdb8bc401ebe2e0b16dc500bd13261342d80d9643ef4dc94a05 [root@vm210 ~]# kubectl get nodes [kubelet-check] It seems like the kubelet isn't running or healthy. [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp [::1]:10248: connect: connection refused. // solve the problem above [root@vm210 ~]#vim /etc/docker/daemon.json { \"exec-opts\": [\"native.cgroupdriver=systemd\"] } [root@vm210 ~]#systemctl daemon-reload [root@vm210 ~]#systemctl restart docker [root@vm210 ~]#systemctl restart kubelet [root@vm211 ~]# kubectl get nodes The connection to the server localhost:8080 was refused - did you specify the right host or port? kubectl version -o json kubectl cluster-info [root@vm211 ~]# kubectl cluster-info To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. The connection to the server localhost:8080 was refused - did you specify the right host or port? [root@vm210 ~] systemctl status kubelet [root@vm210 ~] journalctl -xeu kubelet // Unable to update cni config\" err=\"no networks found in /etc/cni/net.d // if you encounter this problem, just to redo all the activity above on the node.","title":"kubedam"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#summary","text":"What we need to note during the entire installation process is that don't just to search the key you see with command 'systemctl status kubelet' or 'journalctl -u kubelet' we must pay more attention to the args like $KUBELET_EXTRA_ARGS when we encounter some errors. 'Process: 8998 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)'","title":"summary"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#errors","text":"The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp [::1]:10248: connect: connection refused. systemctl restart kubelet [root@vm210 ~]# kubelet --cgroupDriver E0820 13:16:23.223925 31791 server.go:158] \"Failed to parse kubelet flag\" err=\"unknown flag: --cgroupDriver\" EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env remove the arg cgroupDriver systemctl restart kubelet check network ip a cat /etc/resolv.conf","title":"Errors"},{"location":"install-kubernetes-cluster/kubeadm/kubeadm-centos7-install/#references","text":"The kubelet drop-in file for systemd kubelet failed with kubelet cgroup driver: \u201ccgroupfs\u201d is different from docker cgroup driver: \u201csystemd\u201d Configuring each kubelet in your cluster using kubeadm Installing kubeadm Quickstart for Calico on Kubernetes kubeadm\u5b89\u88c5k8s\u5b8c\u6574\u6559\u7a0b","title":"References"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/","text":"VM Install \u00b6 Tip If you are using Macbook, start from here Download images and tools \u00b6 Install virtualbox \u00b6 https://www.virtualbox.org/wiki/Downloads From System Preference -> Security & Privacy, allow Oracle access From Virtualbox -> File -> Host Network Manager, click Create button to create one Install ubuntu iso from below link \u00b6 https://releases.ubuntu.com/20.04/ Installation and configuration \u00b6 Install virtualbox \u00b6 Open virtualbox manager console \u00b6 Ensure you have correct host network manager settings \u00b6 properties->vboxnet0->192.168.34.1/24 If the subnet is different, you can edit and update it Do not enable dhcp Boot new VM \u00b6 Click new button Choose OS as ubuntu 64bit and 30G disk, make sure your #CPU>=2 Start VM, choose the downloaded ubuntu ISO and follow the installation wizard Specify username/password like cadmin/cadmin Install ssh server, enable and start the service Do not install built-in kubenernetes Wait enough long for the os installation complete Shutdown the OS, and set 2nd network adapter \u00b6 Go to VM->settings->network->adapter 2 Enable the adapter and select host only adapter, and choose vboxnet0, vboxnet0 the host network name configured above Login to the system and set ip for second adapter \u00b6 vi /etc/netplan/00-installer-config.yaml network: ethernets: enp0s3: dhcp4: true enp0s8: dhcp4: no addresses: - 192 .168.34.2/24 version: 2 netplan apply Network configuration \u00b6 Now your VM has two adapters: One is NAT which will get an IP automatically, generally it's 10.0.2.15, this interface is for external access from your VM One is host adapter which need create extra ip, which is configured as 192.168.34.2 the reason we need the host adapter and static IP is then we can set this static IP as k8s advertise IP and you can move your VM in different everywhere.(otherwise your VM IP would be changed in different environment) Set no password for sudo \u00b6 %sudo ALL =( ALL:ALL ) NOPASSWD:ALL Swap off \u00b6 swapoff -a vi /etc/fstab remove the line with swap keyword","title":"VM Install"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#vm-install","text":"Tip If you are using Macbook, start from here","title":"VM Install"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#download-images-and-tools","text":"","title":"Download images and tools"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#install-virtualbox","text":"https://www.virtualbox.org/wiki/Downloads From System Preference -> Security & Privacy, allow Oracle access From Virtualbox -> File -> Host Network Manager, click Create button to create one","title":"Install virtualbox"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#install-ubuntu-iso-from-below-link","text":"https://releases.ubuntu.com/20.04/","title":"Install ubuntu iso from below link"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#installation-and-configuration","text":"","title":"Installation and configuration"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#install-virtualbox_1","text":"","title":"Install virtualbox"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#open-virtualbox-manager-console","text":"","title":"Open virtualbox manager console"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#ensure-you-have-correct-host-network-manager-settings","text":"properties->vboxnet0->192.168.34.1/24 If the subnet is different, you can edit and update it Do not enable dhcp","title":"Ensure you have correct host network manager settings"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#boot-new-vm","text":"Click new button Choose OS as ubuntu 64bit and 30G disk, make sure your #CPU>=2 Start VM, choose the downloaded ubuntu ISO and follow the installation wizard Specify username/password like cadmin/cadmin Install ssh server, enable and start the service Do not install built-in kubenernetes Wait enough long for the os installation complete","title":"Boot new VM"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#shutdown-the-os-and-set-2nd-network-adapter","text":"Go to VM->settings->network->adapter 2 Enable the adapter and select host only adapter, and choose vboxnet0, vboxnet0 the host network name configured above","title":"Shutdown the OS, and set 2nd network adapter"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#login-to-the-system-and-set-ip-for-second-adapter","text":"vi /etc/netplan/00-installer-config.yaml network: ethernets: enp0s3: dhcp4: true enp0s8: dhcp4: no addresses: - 192 .168.34.2/24 version: 2 netplan apply","title":"Login to the system and set ip for second adapter"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#network-configuration","text":"Now your VM has two adapters: One is NAT which will get an IP automatically, generally it's 10.0.2.15, this interface is for external access from your VM One is host adapter which need create extra ip, which is configured as 192.168.34.2 the reason we need the host adapter and static IP is then we can set this static IP as k8s advertise IP and you can move your VM in different everywhere.(otherwise your VM IP would be changed in different environment)","title":"Network configuration"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#set-no-password-for-sudo","text":"%sudo ALL =( ALL:ALL ) NOPASSWD:ALL","title":"Set no password for sudo"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/1.vm-install/#swap-off","text":"swapoff -a vi /etc/fstab remove the line with swap keyword","title":"Swap off"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/2.docker-install/","text":"Install docker \u00b6 apt install docker.io Update cgroupdriver to systemd \u00b6 vi /etc/docker/daemon.json { \"exec-opts\" : [ \"native.cgroupdriver=systemd\" ] } systemctl daemon-reload systemctl restart docker","title":"Docker Install"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/2.docker-install/#install-docker","text":"apt install docker.io","title":"Install docker"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/2.docker-install/#update-cgroupdriver-to-systemd","text":"vi /etc/docker/daemon.json { \"exec-opts\" : [ \"native.cgroupdriver=systemd\" ] } systemctl daemon-reload systemctl restart docker","title":"Update cgroupdriver to systemd"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/","text":"Letting iptables see bridged traffic \u00b6 $ cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF $ cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sudo sysctl --system Update the apt package index and install packages needed to use the Kubernetes apt repository: \u00b6 $ sudo apt-get update $ sudo apt-get install -y apt-transport-https ca-certificates curl Install kubeadm \u00b6 $ sudo curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - Add the Kubernetes apt repository \u00b6 $ sudo tee /etc/apt/sources.list.d/kubernetes.list <<-'EOF' deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main EOF Update apt package index, install kubelet, kubeadm and kubectl \u00b6 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubeadm init \u00b6 $ echo \"192.168.34.2 cncamp.com\" >> /etc/hosts $ kubeadm init \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.22.2 \\ --pod-network-cidr = 192 .168.0.0/16 \\ --apiserver-advertise-address = 192 .168.34.2 Copy kubeconfig \u00b6 $ mkdir -p $HOME /.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config $ sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config Untaint master \u00b6 $ kubectl taint nodes --all node-role.kubernetes.io/master- Install calico cni plugin \u00b6 https://docs.projectcalico.org/getting-started/kubernetes/quickstart $ kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml $ kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml if you want to enable containerd during start, set the cri-socket parameter during kubeadm init \u00b6 kubeadm init \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.22.2 \\ --pod-network-cidr = 192 .168.0.0/16 \\ --cri-socket /run/containerd/containerd.sock \\ --apiserver-advertise-address = 192 .168.34.2","title":"Kubernetes Install"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#letting-iptables-see-bridged-traffic","text":"$ cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF $ cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sudo sysctl --system","title":"Letting iptables see bridged traffic"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#update-the-apt-package-index-and-install-packages-needed-to-use-the-kubernetes-apt-repository","text":"$ sudo apt-get update $ sudo apt-get install -y apt-transport-https ca-certificates curl","title":"Update the apt package index and install packages needed to use the Kubernetes apt repository:"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#install-kubeadm","text":"$ sudo curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -","title":"Install kubeadm"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#add-the-kubernetes-apt-repository","text":"$ sudo tee /etc/apt/sources.list.d/kubernetes.list <<-'EOF' deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main EOF","title":"Add the Kubernetes apt repository"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#update-apt-package-index-install-kubelet-kubeadm-and-kubectl","text":"$ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl","title":"Update\u00a0apt\u00a0package index, install kubelet, kubeadm and kubectl"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#kubeadm-init","text":"$ echo \"192.168.34.2 cncamp.com\" >> /etc/hosts $ kubeadm init \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.22.2 \\ --pod-network-cidr = 192 .168.0.0/16 \\ --apiserver-advertise-address = 192 .168.34.2","title":"kubeadm init"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#copy-kubeconfig","text":"$ mkdir -p $HOME /.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config $ sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config","title":"Copy kubeconfig"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#untaint-master","text":"$ kubectl taint nodes --all node-role.kubernetes.io/master-","title":"Untaint master"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#install-calico-cni-plugin","text":"https://docs.projectcalico.org/getting-started/kubernetes/quickstart $ kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml $ kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml","title":"Install calico cni plugin"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/3.k8s-install/#if-you-want-to-enable-containerd-during-start-set-the-cri-socket-parameter-during-kubeadm-init","text":"kubeadm init \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.22.2 \\ --pod-network-cidr = 192 .168.0.0/16 \\ --cri-socket /run/containerd/containerd.sock \\ --apiserver-advertise-address = 192 .168.34.2","title":"if you want to enable containerd during start, set the cri-socket parameter during kubeadm init"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/resize-vm/","text":"fdisk \u00b6 fdisk /dev/sda p - partition n - new Create new pv \u00b6 pvcreate /dev/sda4 vgdisplay Add new pv to vg \u00b6 vgextend ubuntu-vg /dev/sda4 Check rootfs lv path \u00b6 vgdisplay lvdisplay Resize root fix \u00b6 lvextend --size +19.99G --resizefs /dev/ubuntu-vg/ubuntu-lv","title":"Resize VM"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/resize-vm/#fdisk","text":"fdisk /dev/sda p - partition n - new","title":"fdisk"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/resize-vm/#create-new-pv","text":"pvcreate /dev/sda4 vgdisplay","title":"Create new pv"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/resize-vm/#add-new-pv-to-vg","text":"vgextend ubuntu-vg /dev/sda4","title":"Add new pv to vg"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/resize-vm/#check-rootfs-lv-path","text":"vgdisplay lvdisplay","title":"Check rootfs lv path"},{"location":"install-kubernetes-cluster/kubeadm/k8s-by-kubeadm/resize-vm/#resize-root-fix","text":"lvextend --size +19.99G --resizefs /dev/ubuntu-vg/ubuntu-lv","title":"Resize root fix"}]}